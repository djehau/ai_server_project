#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã GPU –≤ –ø—Ä–æ–µ–∫—Ç–µ VTuber AI
"""
import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent))

def test_gpu():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU...")
    
    try:
        import torch
        print(f"‚úÖ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
        
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.version.cuda}")
            print(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
                
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç—É—é –æ–ø–µ—Ä–∞—Ü–∏—é –Ω–∞ GPU
            print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ GPU...")
            device = torch.device('cuda:0')
            
            # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é –º–∞—Ç—Ä–∏—Ü—É –Ω–∞ GPU
            x = torch.randn(1000, 1000, device=device)
            y = torch.randn(1000, 1000, device=device)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ
            result = torch.mm(x, y)
            print(f"‚úÖ –ú–∞—Ç—Ä–∏—á–Ω–æ–µ —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞ GPU –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result.shape} tensor –Ω–∞ {result.device}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            memory_allocated = torch.cuda.memory_allocated() / 1024**3
            memory_cached = torch.cuda.memory_reserved() / 1024**3
            print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_allocated:.2f} GB (–≤—ã–¥–µ–ª–µ–Ω–æ), {memory_cached:.2f} GB (–∫—ç—à–∏—Ä–æ–≤–∞–Ω–æ)")
            
        else:
            print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU")
            return False
            
    except ImportError:
        print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
        
    return True

def test_llm_service():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç LLM —Å–µ—Ä–≤–∏—Å"""
    print("\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM —Å–µ—Ä–≤–∏—Å–∞...")
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º LLM handler
        sys.path.append(str(Path(__file__).parent / "services"))
        from llm_service import LLMHandler
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        handler = LLMHandler()
        print(f"‚úÖ LLM Handler —Å–æ–∑–¥–∞–Ω, —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {handler.device}")
        
        if handler.device == "cuda":
            print("‚úÖ LLM —Å–µ—Ä–≤–∏—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU")
            return True
        else:
            print("‚ö†Ô∏è  LLM —Å–µ—Ä–≤–∏—Å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ LLM —Å–µ—Ä–≤–∏—Å–∞: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üéØ VTuber AI - –¢–µ—Å—Ç GPU\n")
    
    gpu_ok = test_gpu()
    llm_ok = test_llm_service()
    
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"   GPU: {'‚úÖ OK' if gpu_ok else '‚ùå Fail'}")
    print(f"   LLM: {'‚úÖ OK' if llm_ok else '‚ùå Fail'}")
    
    if gpu_ok and llm_ok:
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã! –í–∞—à –ø—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ —Å GPU.")
    else:
        print("\n‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA.")
        print("   –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124")

if __name__ == "__main__":
    main()
